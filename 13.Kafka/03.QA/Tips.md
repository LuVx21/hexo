<details>
<summary>点击展开目录</summary>
<!-- TOC -->


<!-- /TOC -->
</details>

**什么是Apache Kafka?**

Apach Kafka是一款分布式流处理框架, 用于实时构建流处理应用.

它有一个核心的功能广为人知, 即作为企业级的消息引擎被广泛使用

Apache Kafka 一路发展到现在, 已经由最初的`分布式提交日志系统`逐渐演变成了`实时流处理框架`.

主要基于事务日志设计.

**Kafka 的设计时什么样的?**

Kafka 将消息以 topic 为单位进行归纳

将向 Kafka topic 发布消息的程序成为 producers.

将预订 topics 并消费消息的程序成为 consumer.

Kafka 以集群的方式运行, 可以由一个或多个服务组成, 每个服务叫做一个 broker.

producers 通过网络将消息发送到 Kafka 集群, 集群向消费者提供消息

**kafka的message格式是什么样的**

一个Kafka的Message由一个固定长度的header和一个变长的消息体body组成

header部分由一个字节的magic(文件格式)和四个字节的CRC32(用于判断body消息体是否正常)构成.

当magic的值为1的时候, 会在magic和crc32之间多一个字节的数据: attributes(保存一些相关属性, 比如是否压缩, 压缩格式等等);

如果magic的值为0, 那么不存在attributes属性, body是由N个字节构成的一个消息体, 包含了具体的key/value消息.

2:

消息由一个固定长度的头部和可变长度的字节数组组成.

头部包含了一个版本号和 CRC32 校验码.

* 消息长度: 4 bytes (value: 1 + 4 + n)
* 版本号: 1 byte, magic(文件格式)
* CRC 校验码: 4 bytes, 用于判断body消息体是否正常
* 具体的消息: n bytes

---

**数据传输的事务定义有哪三种?**

数据传输的事务定义通常有以下三种级别:

(1)最多一次: 消息不会被重复发送, 最多被传输一次, 但也有可能一次不传输

(2)最少一次: 消息不会被漏发送, 最少被传输一次, 但也有可能被重复传输

(3)精确的一次(Exactly once): 消息既不重复也不丢失, 每个消息都仅被传输一次

**Kafka 判断一个节点是否还活着有那两个条件?**

(1)节点必须可以维护和 ZooKeeper 的连接, Zookeeper 通过心跳机制检查每个节点的连接

(2)如果节点是个 follower, 它必须能及时的同步 leader 的写操作, 延时不能太久

作者: 摘星不想说话
链接: https://juejin.im/post/6844903889003610119
来源: 掘金
著作权归作者所有.
商业转载请联系作者获得授权, 非商业转载请注明出处.



**如果副本长时间不在ISR中, 这说明什么?**

如果副本长时间不在ISR中, 这表示Follower副本无法及时跟上Leader副本的进度.

通常情况下, 你需要查看Follower副本所在的Broker与Leader副本的连接情况以及Follower副本所在Broker上的负载情况.

**Kafka为什么不像Redis和MySQL那样支持读写分离?**

*1.使用场景* 

对于那种读操作很多而写操作相对不频繁的负载类型而言, 采用读写分离是非常不错的方案: 可以添加很多从库横向扩展, 提升读操作性能.

反观Kafka, 它的主要场景还是在流式生产消费/消息引擎, 而不是以数据存储的方式对外提供读服务, 通常涉及频繁地生产消息和消费消息, 这不属于典型的读多写少场景. 因此, 读写分离方案在这个场景下并不太适合.

*2.副本机制实现方案*

Kafka副本机制使用的是异步消息拉取, 因此存在Leader和Follower之间的不一致性. 

如果要采用读写分离, 必然要处理副本滞后引入的一致性问题: 比如如何实现Read-your-writes, 如何保证单调读(Monotonic Reads)以及处理消息因果顺序颠倒的问题. 

相反, 如果不采用读写分离, 所有客户端读写请求都只在Leader上处理, 也就没有这些问题了. 

当然, 最后的全局消息顺序颠倒的问题在Kafka中依然存在, 常见的解决办法是使用单分区, 其他的方案还有Version Vector, 但是目前Kafka没有提供.


