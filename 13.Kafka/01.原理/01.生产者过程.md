<details>
<summary>点击展开目录</summary>
<!-- TOC -->

- [生产者](#生产者)
- [基本流程](#基本流程)
    - [内部实现](#内部实现)
- [原理](#原理)
    - [分区策略](#分区策略)
    - [可靠性保证](#可靠性保证)
- [分区器](#分区器)

<!-- /TOC -->
</details>

## 生产者

支持同步/异步生产消息, 能做到既不丢失也不重复

生产消息时, 以下三个配置是必需的:
* `bootstrap.servers`: 指定 broker 的地址清单
* `key.serializer`: 指定键的序列化器;
* `value.serializer`: 指定值的序列化器

## 基本流程

![](https://gitee.com/LuVx/img/raw/master/kafka/kafka_producer_flow.png)

> 图上可知, 消息的发送, 需要经过拦截器, 序列化器和分区器, 最终由累加器批量发送至 Broker

1. 创建`ProducerRecord`对象, 其中包含消息的主题(topic)和值(value), 还可以根据需要指定键值(key)或者分区(partition)
2. 生产者会对key和value序列化成字节数组, 然后发送给 partitioner(分区器)
3. 如果指定了分区, 那么分区器返回该分区, 如果没有则会基于key计算出一个分区, 如果没有指定key, 则会以轮询的方式指定分区
4. 此时已经能够确定消息的主题和分区, 之后将消息添加到相同`topic+partition`的批量消息中, 另一个线程会将这些消息发送到对应的Broker
5. broker接收到后, 如果成功写入则会返回一个包含主题, 分区, 偏移量信息的`RecordMetadata`对象, 否则则会返回异常
6. 生产者接收到返回后, 可以对消息或异常进行处理

### 内部实现

消息格式: 每个消息是一个`ProducerRecord`对象, 必须指定消息所属的Topic和消息值Value, 此外还可以指定消息所属的Partition以及消息的Key.

1. 序列化ProducerRecord
2. 如果ProducerRecord中指定了Partition, 则Partitioner不做任何事情; 否则, Partitioner根据消息的key得到一个Partition. 这是生产者就知道向哪个Topic下的哪个Partition发送这条消息.
3. 消息被添加到相应的batch中, 独立的线程将这些batch发送到Broker上
4. broker收到消息会返回一个响应. 如果消息成功写入Kafka, 则返回`RecordMetaData`对象, 该对象包含了Topic信息, Patition信息, 消息在Partition中的Offset信息; 若失败, 返回一个错误

Producer 发送消息采用的是异步发送的方式.

在消息发送的过程中, 涉及到两个线程: `main`线程和`Sender`线程, 以及一个线程共享变量`RecordAccumulator`.

`main`线程将消息发送给 `RecordAccumulator`, `Sender`线程不断从`RecordAccumulator`中拉取消息发送到 Kafka Broker

## 原理

### 分区策略

* 若指定了 Partition, 则直接写入到指定的 Partition
* 若未指定 Partition 但指定了 Key, 则通过对 Key 的 Hash 值与 Partition 数量取模
* 若 Partition 和 Key 都未指定, 则使用轮询算法选出一个 Partition


### 可靠性保证

生产者发送消息时有两种模式:

同步生产模式: 发出消息后阻塞等待生产结果, 收到后才进行下一个消息的生产

异步生产模式: 一直往缓冲区写, 然后批量写到队列中去

异步的显著特点即是吞吐量高, 但可能出现消息丢失的问题

生产者发送数据到分区后, 分区会向生产者发送ack确认收到消息


可靠性的保证依靠以下几点:

**1. ack应答机制**

`acks`的配置支持三种级别, 可以针对数据可靠性和吞吐量进行权衡:

* `0`: 不等待broker的ack, broker收到消息未写入磁盘就发送ack, 此时Producer延迟最低, 存在极大的丢数据的可能性, 如leader故障, 此消息将会丢失
* `1`: 等待broker的ack, 在leader落盘成功后发送ack, 如果follower同步成功前, leader故障, 此消息将会丢失
* `-1`: 等待broker的ack, 在leader和所有follower全部落盘成功后发送ack, 具有最强的消息持久化保障, 如果同步完成后leader故障, 导致ack未成功发送, 会导致重发造成消息重复

阅读: [副本机制](../01.原理/04.副本机制.md)

**2. ISR**

上述`acks=-1`时, 如果某个follower故障, 迟迟不能和leader同步消息, 那么leader则会等待下去不会发送ack

为解决此问题, 提出了`ISR(in-sync replica set)`方案:

每一个Partition都可能会有1个或者多个Replica, 其中一个被选举为Leader, 其他为Follower, leader则会跟踪与其保持同步的Replica列表, 该列表即为ISR(一个和leader保持同步的follower的列表). 当ISR中的所有follower完成同步就发送ack

如果某个follower长时间未和leader同步消息, 则将其从ISR中删除, 这个时间由`replica.lag.time.max.ms`参数配置

leader故障后, 则从ISR中的选举新的leader

**3. LEO/HW**

LEO: `Log End Offset`, 每个副本最大的offset

HW: `High Watermark`, 消费者能见到的最大的 offset, HW之前的消息才对消费者可见, 为ISR中最小的LEO, 保证了 Partition 的 Follower 与 Leader 间数据的一致性

![hw](https://gitee.com/LuVx/img/raw/master/kafka/kafka_hw.png)
> ISR 中, `min(LEO)`到`max(LEO)`之间的消息还没有完全同步到所有副本中

这是保证数据一致性的原理, 这里说的一致性, 是指分区各副本在发生 leader 变更前后, 消费者读到的数据是一致的

leader 和 follower 同步细节:

follower故障:

故障时会被踢出ISR, 待恢复后, 读取故障前的HW, 将大于HW的消息全部删除, 重新从leader开始同步

等到该follower的LEO大于等于分区此时的HW后, 即该follower已经追上了所有副本中的最慢的后, 再加入ISR中

leader故障:

故障时会从ISR中选出一个leader, 为了保证各副本间数据一致, 各个follower会将各自高于HW部分的消息删除掉, 然后从新leader同步消息

## 分区器

默认分区机制:
* 没指定key, 均衡分布到各个分区
* 指定了key, 对key进行hash计算出分区

可以自定义分区器:

实现 `Partitioner` 接口

使用时, 在配置中指定自定义的分区器
