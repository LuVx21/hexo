<details>
<summary>点击展开目录</summary>
<!-- TOC -->

- [消费者组](#消费者组)
- [消费者](#消费者)
- [原理](#原理)
    - [基本流程](#基本流程)
    - [再均衡](#再均衡)
- [可靠性](#可靠性)
- [位移管理](#位移管理)
    - [自动提交](#自动提交)
    - [手动提交偏移量](#手动提交偏移量)
- [使用](#使用)
    - [线程不安全](#线程不安全)
    - [监听消费组再均衡](#监听消费组再均衡)

<!-- /TOC -->
</details>

## 消费者组

Kafka提供的可扩展且具有容错性的消费者机制

消费者组是一个由多个消费者实例构成的组. 同一个组下的每个实例都共享一个公共的ID, 即Group ID, 并被分配不同的订阅分区.

所有消费者共同订阅若干个主题, 协调在一起来消费订阅主题的所有分区. 

每个分区只能由同一个消费组内的一个消费者实例来消费.

当某个实例挂掉的时候, 其他实例会自动地承担起它负责消费的分区

**消费者组的位移提交机制**

## 消费者

一个消费者可以消费多个topic的消息, 也可以消费同一个topic的多个分区的消息

一个分区可以被多个消费者消费, 但不能被同一个消费组的多个消费者消费, 换句话说, 消费同一个分区的多个消费者要分布在不同的消费组中

如果一个消费组中消费者的数量多于分区数, 则会出现消费者空闲的情况, 因此不建议创建比分区数多的消费者

基于消费组的概念, 可以发现某个分区的消息可以被不同的消费组多次消费, 所以不同的消费组消费到哪个offset是怎样记录的?

Partition 会为每个消费组保存一个偏移量, 记录消费到的位置, 如图:

![](https://gitee.com/LuVx/img/raw/master/kafka/kafka_Partition与消费模型.png)

这些信息都记录在: `__consumer_offsets`, 系统内部topic

* 无需手动干预, 主要作用是负责注册消费者(保存消费者元数据)以及保存位移值
* 内部存储消费组对某个topic的某个分区的消费进度, 以`消费组名+topic名+分区 id`为key计算出存储 offset 的分区id
* Kafka的`GroupCoordinator`组件提供对该主题完整的管理功能, 包括该主题的创建, 写入, 读取和Leader维护等

消息的删除: 消息的删除与是否消费无关, 直到过期, 在有效期内可以被任何消费组随意消费, 之后到达过期时间被自动删除

消费消息时, 以下三个配置是必需的:

* `bootstrap.servers`: 指定 broker 的地址清单
* `key.deserializer`: 指定键的反序列化器
* `value.deserializer`: 指定值的反序列化器

## 原理

consumer 采用 `pull(拉)`模式从 broker 中读取数据,

`push`模式的消费形式无法满足不同消费能力的消费者, 因为消费速率由broker控制, 而`pull`模式则可以由消费者自主控制消费速率

### 基本流程

pull 方式拉取消息, 向`__consumer_offset` topic中发送消息, 记录消费者对分区的消费偏移量, 即消费到哪个位置

这个位置在再均衡时发挥着重要作用, 因为再均衡后某分区对应的消费者可能就不是之前的那一个, 因此就会去这个特殊的 topic 中, 以`消费组名+topic 名+分区 id`找到上一次消费的位置继续消费, 因此正确提交消费偏移量是至关重要的

### 再均衡

为消费者分配订阅的分区

消费组内增减消费者时, 增加的消费者会消费一个或多个分区, 减去的消费者负责的分区会分给其他消费者, 这样的一个维护过程被称为再均衡

在此期间, 无法对消费者提供服务, 会造成短暂的不可用, 降低性能

再均衡的触发条件:
1. 组成员发生变更(新 consumer 加入组, 已有 consumer 主动离开组或已有 consumer 崩溃)
2. 订阅主题数发生变更
3. 订阅主题的分区数发生变更

## 可靠性

不丢失不重复

提交的偏移量不正确, 如小于最后一次消费消息的偏移量, 那么这两个偏移量间的消息则会重复消费, 如果大于, 则两者间的消息会丢失

消息丢失: 如获取到某消息后, 自动提交了offset, 但出现异常导致没有消费该消息, 恢复后就会从下一个offset开始消费

消息重复: 上一次提交偏移量后, 下一次之前发生再均衡, 之后就会从最后一次提交的偏移量后开始消费, 而这个偏移量到发生再均衡时之间的消息都会重复消费

## 位移管理

### 自动提交

```Java
// 是否开启自动提交
props.put("enable.auto.commit", "true");
// 自动提交时间间隔
props.put("auto.commit.interval.ms", "1000");
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    KafkaUtils.print(records);
}
```

### 手动提交偏移量

手动提交的话, 也是有可能带来重复消费的风险, 如消费完成了, 提交offset时出现异常, 恢复后再次消费了该消息

**同步提交**

```Java
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    KafkaUtils.print(records);
    consumer.commitSync();
}
```

如果提交失败, 同步方式会进行重试, 最大限度保证提交成功, 当然伴随着吞吐量的下降

**异步提交**

```Java
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    KafkaUtils.print(records);
    consumer.commitAsync(
            (offsets, exception) -> {
                if (exception != null) {
                    log.error("commit exception! offset:{}", offsets);
                }
            }
    );
}
```

异步方式在提交失败时不会进行重试, 这是异步模式本身决定的, 前一提交的失败不会阻塞后一提交,

如果后一提交成功, 对前一提交进行重试, 如果重试成功则会覆盖掉后面的offset

**提交指定偏移量**

```Java
Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>(8);
while (true) {
    ConsumerRecords<String, String> records1 = consumer.poll(Duration.ofMillis(100));
    // KafkaUtils.print(records);
    for (ConsumerRecord<String, String> record : records1) {
        TopicPartition tp = new TopicPartition(record.topic(), record.partition());
        OffsetAndMetadata om = new OffsetAndMetadata(record.offset() + 1, "nothing");
        offsets.put(tp, om);
    }
    // consumer.commitSync(offsets);
    consumer.commitAsync(offsets, null);
}
```

同样的也支持同步/异步方式

## 使用

### 线程不安全

Java Consumer是双线程的设计. 一个线程是用户主线程, 负责获取消息；另一个线程是心跳线程, 负责向Kafka汇报消费者存活情况. 将心跳单独放入专属的线程, 能够有效地规避因消息处理速度慢而被视为下线的“假死”情况.

单线程获取消息的设计能够避免阻塞式的消息获取方式. 单线程轮询方式容易实现异步非阻塞式, 这样便于将消费者扩展成支持实时流处理的操作算子. 因为很多实时流处理操作算子都不能是阻塞式的. 另外一个可能的好处是, 可以简化代码的开发. 多线程交互的代码是非常容易出错的.

Kafka 的 Consumer 客户端是线程不安全的, 为了保证线程安全, 并提升消费性能, 可以在 Consumer 端采用类似 Reactor 的线程模型来消费数据

### 监听消费组再均衡

代码如下:

```Java
consumer.subscribe(Arrays.asList(KafkaConfig.topic), new ConsumerRebalanceListener() {
            /**
             * 停止消费消息后, 再均衡前调用
             * @param partitions
             */
            @Override
            public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
                log.info("再均衡开始:{}", LocalDateTime.now());
                consumer.commitSync();
            }

            /**
             * 再均衡, 开始消费消息前调用
             * @param partitions
             */
            @Override
            public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
                log.info("再均衡结束:{}", LocalDateTime.now());
                for (TopicPartition partition : partitions) {
                    // 定位到最近提交的 offset 位置继续消费
                    consumer.seek(partition, getOffset(partition));
                }
            }
        }
);
```
